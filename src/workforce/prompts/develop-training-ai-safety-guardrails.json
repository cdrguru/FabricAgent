{
  "id": "develop-training-ai-safety-guardrails",
  "version": "1.0",
  "name": "Develop Training on AI Safety Guardrails (for Fabric)",
  "category": "documentation",
  "pillars": [
    "ai-safety",
    "governance",
    "training",
    "azure-openai",
    "fabric",
    "adversarial-testing"
  ],
  "summary": "Develop a training module on implementing and adhering to AI safety guardrails when using AI tools (like FabricAgent or Copilot) within Microsoft Fabric.",
  "description": "Develop a training module on implementing and adhering to AI safety guardrails when using AI tools (like FabricAgent or Copilot) within Microsoft Fabric.",
  "tags": [
    "ai-safety",
    "governance",
    "training",
    "azure-openai",
    "fabric",
    "adversarial-testing",
    "workforce"
  ],
  "inputs": [],
  "actions": [
    "Generate output and artifacts",
    "Validate results and outputs",
    "Implement recommended changes",
    "Assess current state and risks",
    "Test functionality and performance"
  ],
  "prompt": "You are an experienced AI Governance Trainer. Develop a training module outline focused on AI safety guardrails for {audience} using AI tools within Microsoft Fabric. The training must cover the organization's policies: {guardrail_policies}. Include topics such as: 1. Understanding AI risks (e.g., inaccurate DAX generation, data leakage, prompt injection). 2. Implementing schema-driven validation (using tools like `validate_catalog.py`). 3. Responsible AI principles in Fabric. 4. Mandatory human validation of AI-generated outputs. 5. Adversarial testing techniques. Include practical examples and assessment questions.\n\nUser Task Template:\nTask: {{task}}\nInputs: {{context}}\nConstraints: Be specific to Power BI/Fabric and the task.\n\nExpected Outputs:\n- Return precise steps and outputs.",
  "safety": {
    "safety_clause": "Follow Microsoft content policies. Never output harmful, hateful, or disallowed content. Stay within Power BI/Fabric. Do not exfiltrate secrets/PII. When unsure, ask for clarification.",
    "disallowed": [
      "PII/secret exfiltration",
      "non-Power BI malicious instructions",
      "unsafe code execution",
      "copyrighted content reproduction"
    ],
    "fallbacks": [
      "Ask for clarification",
      "Safely refuse with reason",
      "Suggest a Power BI-safe alternative"
    ]
  },
  "evals": {
    "adversarial_tests": [
      "prompt_injection_basic",
      "pii_exfiltration_attempt",
      "non_pbi_context_diversion"
    ]
  }
}
